{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd14df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dotenv\n",
    "from twon_lss.utility import LLM, Message, Chat\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c6e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = dotenv.dotenv_values(\"../\" * 3 + \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341940a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1393050/2792471165.py:1: DtypeWarning:\n",
      "\n",
      "Columns (2,3,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/FolloweeIDs2_tweets_df_AugustPull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f555775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the profiler prompts\n",
    "with open(\"../data/profiler.bio.txt\", \"r\") as f:\n",
    "    BIO_PROFILER_PROMPT = f.read()\n",
    "\n",
    "with open(\"../data/profiler.cognition.txt\", \"r\") as f:\n",
    "    COGNITION_PROFILER_PROMPT = f.read()\n",
    "\n",
    "# Load the instructions\n",
    "with open(\"../data/agents.instructions.json\", \"r\") as f:\n",
    "    INSTRUCTIONS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69fe30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_posts_per_day(df):\n",
    "    num_days = (pd.to_datetime(df[\"created_at\"]).max() - pd.to_datetime(df[\"created_at\"]).min()).days\n",
    "    total_posts = len(df)\n",
    "    posts_per_day = total_posts / num_days if num_days > 0 else 0\n",
    "    return posts_per_day \n",
    "\n",
    "\n",
    "def df_to_history_string(df) -> str:\n",
    "    \"\"\"Parse the history from the json format to the Message format.\"\"\"\n",
    "    history_string = \"\"\n",
    "    for i, message in df.iterrows():\n",
    "        history_string += f\">Tweet written by you: {message['full_text']}\\n\"\n",
    "    return history_string\n",
    "\n",
    "\n",
    "def df_to_llm_history(df) -> list[Message]:\n",
    "    \"\"\"Parse the history from the json format to the Message format.\"\"\"\n",
    "    parsed_history = []\n",
    "\n",
    "    for i, message in df.iterrows():\n",
    "            parsed_history.append({\"role\": \"user\", \"content\": f\"{INSTRUCTIONS['actions']['post_prompt']}\"})\n",
    "            parsed_history.append({\"role\": \"assistant\", \"content\": f\"{message['full_text']}\"})\n",
    "\n",
    "    return parsed_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b58eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Profiler LLM\n",
    "AGENT_LLM = LLM(api_key=ENV[\"HF_TOKEN\"], model=\"Qwen/Qwen3-235B-A22B-Instruct-2507:cerebras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40382daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing agent personas\n",
    "with open(\"../data/agents.personas.json\", \"r\") as f:\n",
    "    PERSONA_PROFILES = json.load(f)\n",
    "\n",
    "#PERSONA_PROFILES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c781d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/34696 [00:04<2:31:46,  3.81it/s]"
     ]
    }
   ],
   "source": [
    "for screen_name in tqdm(df[\"screen_name\"].unique().tolist()):\n",
    "    if any(persona.get(\"screen_name\") == screen_name for persona in PERSONA_PROFILES):\n",
    "        continue\n",
    "\n",
    "    persona_dict = {\"screen_name\": screen_name}\n",
    "\n",
    "    # Filter to original tweets only\n",
    "    filtered_df = df[df[\"screen_name\"] == screen_name].drop_duplicates(subset=[\"full_text\"])\n",
    "\n",
    "    filtered_df[\"reply_to_user\"] = filtered_df[\"reply_to_user\"].astype(str)\n",
    "    filtered_df = filtered_df[filtered_df[\"reply_to_user\"] == \"nan\"]\n",
    "\n",
    "    filtered_df[\"retweeted_user_ID\"] = filtered_df[\"retweeted_user_ID\"].astype(str)\n",
    "    filtered_df = filtered_df[filtered_df[\"retweeted_user_ID\"] == \"nan\"]\n",
    "\n",
    "    filtered_df = filtered_df.sort_values(by=\"created_at\").reset_index(drop=True)\n",
    "\n",
    "    # Calculate posts per day\n",
    "    posts_per_day = determine_posts_per_day(filtered_df)\n",
    "\n",
    "    # Drop any posts that contains an URL\n",
    "    filtered_df = filtered_df[~filtered_df[\"full_text\"].str.contains(\"http\")].reset_index(drop=True)\n",
    "    if len(filtered_df) < 5:\n",
    "        continue\n",
    "\n",
    "    bio = AGENT_LLM.generate(\n",
    "        Chat([\n",
    "            Message(role=\"user\", content=BIO_PROFILER_PROMPT.format(history=df_to_history_string(filtered_df))),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    cognition = AGENT_LLM.generate(\n",
    "        Chat([\n",
    "            Message(role=\"user\", content=COGNITION_PROFILER_PROMPT.format(history=df_to_history_string(filtered_df), bio=bio))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    persona_dict[\"bio\"] = bio\n",
    "    persona_dict[\"cognition\"] = cognition\n",
    "    persona_dict[\"history\"] = df_to_llm_history(filtered_df)\n",
    "    persona_dict[\"posts_per_day\"] = posts_per_day\n",
    "\n",
    "    PERSONA_PROFILES.append(persona_dict)\n",
    "\n",
    "    # Save as JSON\n",
    "    with open(\"../data/agents.personas_dummy.json\", \"w\") as f:\n",
    "        json.dump(PERSONA_PROFILES, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TWON-LSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
